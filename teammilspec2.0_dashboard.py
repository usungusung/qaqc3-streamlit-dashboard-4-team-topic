import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import joblib
import json
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# =========================
# Color System (Theme)
# =========================
DEFECT_RED  = "#E74C3C"
OK_GRAY     = "#9CA3AF"
NEUTRAL_GRAY = "#6B7280"  # ê·¸ë˜í”„/ì •ë³´ìš© ì¤‘ë¦½ìƒ‰


# =========================================================
# 0) Page Config + Sidebar UI CSS
# =========================================================
st.set_page_config(page_title="ë°€ìŠ¤í™ 2.0", layout="wide")

st.markdown(
    """
<style>
/* ğŸ”¹ ë¼ë””ì˜¤ ê·¸ë£¹ ì „ì²´ ê°„ê²© */
section[data-testid="stSidebar"] div[role="radiogroup"] {
    display: flex;
    flex-direction: column;
    gap: 0.5rem;
}

/* ğŸ”¹ ê° ë¼ë””ì˜¤ í•­ëª©ì„ ì¹´ë“œì²˜ëŸ¼ ë³´ì´ë„ë¡ ë³€í˜• */
section[data-testid="stSidebar"] div[role="radiogroup"] > label {
    background-color: #ffffff;
    padding: 12px 16px;
    border-radius: 10px;
    border: 1px solid #d0d4dd;
    cursor: pointer;
    transition: all 0.15s ease;
    box-shadow: 0px 1px 2px rgba(0,0,0,0.08);
}

/* ğŸ”¹ ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ë©´ ì…ì²´ê° */
section[data-testid="stSidebar"] div[role="radiogroup"] > label:hover {
    background-color: #f5f7ff;
    border-color: #a5b4fc;
    box-shadow: 0px 2px 6px rgba(0,0,0,0.12);
}

/* ğŸ”¹ ì„ íƒëœ í•­ëª© ê°•ì¡° */
section[data-testid="stSidebar"] div[role="radiogroup"] > label[data-selected="true"] {
    background-color: #eef2ff;
    border: 2px solid #6366f1;
    box-shadow: 0px 2px 6px rgba(99, 102, 241, 0.25);
}

/* ğŸ”¹ í…ìŠ¤íŠ¸ ì¡°ê¸ˆ í‚¤ìš´ë‹¤ */
section[data-testid="stSidebar"] div[role="radiogroup"] span {
    font-size: 16px !important;
    font-weight: 600 !important;
}
</style>
""",
    unsafe_allow_html=True
)

st.caption("ëŒ€ì‹œë³´ë“œ í”„ë¡œì íŠ¸")
st.title("ì–‘ê·¹ ì‚°í™” í”¼ë§‰ ë°ì´í„° ê¸°ë°˜ ë¶ˆëŸ‰ ì˜ˆì¸¡ ë¶„ì„")


# =========================================================
# 1) Data Load
# =========================================================
@st.cache_data
def load_raw_data(csv_path: str = "ë°©ì‚°í†µí•©ë°ì´í„°ì…‹.csv") -> pd.DataFrame:
    mil = pd.read_csv(csv_path)
    mil["pk_datetime"] = pd.to_datetime(mil["pk_datetime"], errors="coerce")
    mil.dropna(subset=["pk_datetime"], inplace=True)
    return mil

mil_raw = load_raw_data()


# =========================================================
# 2) Common Feature Engineering
# =========================================================
def add_time_features(mil: pd.DataFrame) -> pd.DataFrame:
    mil = mil.sort_values(["sequence_index", "pk_datetime"]).copy()

    # lag
    mil["ampere_lag1"] = mil.groupby("sequence_index")["ampere"].shift(1)
    mil["volt_lag1"] = mil.groupby("sequence_index")["volt"].shift(1)
    mil["temperature_lag1"] = mil.groupby("sequence_index")["temperature"].shift(1)

    # rolling mean/std (window=3, shift=1)
    mil["ì „ë¥˜ì´ë™í‰ê· "] = (
        mil.groupby("sequence_index")["ampere"]
        .rolling(window=3).mean().shift(1)
        .reset_index(level=0, drop=True)
    )
    mil["ì „ì••ì´ë™í‰ê· "] = (
        mil.groupby("sequence_index")["volt"]
        .rolling(window=3).mean().shift(1)
        .reset_index(level=0, drop=True)
    )
    mil["ì˜¨ë„ì´ë™í‰ê· "] = (
        mil.groupby("sequence_index")["temperature"]
        .rolling(window=3).mean().shift(1)
        .reset_index(level=0, drop=True)
    )

    mil["ì „ë¥˜ì´ë™í‘œì¤€í¸ì°¨"] = (
        mil.groupby("sequence_index")["ampere"]
        .rolling(window=3).std().shift(1)
        .reset_index(level=0, drop=True)
    )
    mil["ì „ì••ì´ë™í‘œì¤€í¸ì°¨"] = (
        mil.groupby("sequence_index")["volt"]
        .rolling(window=3).std().shift(1)
        .reset_index(level=0, drop=True)
    )
    mil["ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨"] = (
        mil.groupby("sequence_index")["temperature"]
        .rolling(window=3).std().shift(1)
        .reset_index(level=0, drop=True)
    )

    # diff by sequence
    mil["â–³ì „ë¥˜"] = mil.groupby("sequence_index")["ampere"].diff()
    mil["â–³ì „ì••"] = mil.groupby("sequence_index")["volt"].diff()
    mil["â–³ì˜¨ë„"] = mil.groupby("sequence_index")["temperature"].diff()

    return mil


def compute_quality_metrics(mil: pd.DataFrame, k: float = 3.0):
    df = mil.copy()
    df["is_defect"] = (df["failure"] == -1).astype(int)

    defect_rate = df["is_defect"].mean()
    segment_defect_rate = df.groupby("sequence_index")["is_defect"].mean()

    df_time = df.set_index("pk_datetime")
    hourly_defect_rate = df_time["is_defect"].resample("1H").mean()

    mask_def = df["is_defect"] == 1
    mask_ok = df["is_defect"] == 0

    volt_diff = df.loc[mask_def, "volt"].mean() - df.loc[mask_ok, "volt"].mean()
    amp_diff = df.loc[mask_def, "ampere"].mean() - df.loc[mask_ok, "ampere"].mean()
    temp_diff = df.loc[mask_def, "temperature"].mean() - df.loc[mask_ok, "temperature"].mean()

    volt_std_def = df.loc[mask_def, "volt"].std()
    volt_std_ok = df.loc[mask_ok, "volt"].std()
    ISI_volt = np.nan if (np.isnan(volt_std_ok) or volt_std_ok == 0) else (volt_std_def / volt_std_ok)

    DRI_current = df.loc[mask_def, "â–³ì „ë¥˜"].abs().mean()
    MSK_temp = df.loc[mask_def, "ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨"].mean()

    def _calc_ooc_and_drift(data: pd.DataFrame, value_col: str, ma_col: str, std_col: str, time_col: str, k: float):
        if not all(c in data.columns for c in [value_col, ma_col, std_col, time_col]):
            return np.nan, np.nan

        s = data[[time_col, value_col, ma_col, std_col]].dropna().sort_values(time_col)
        if len(s) == 0:
            return np.nan, np.nan

        dev = (s[value_col] - s[ma_col]).abs()
        limit = k * s[std_col]
        ooc_ratio = (dev > limit).mean()

        drift = np.nan
        if len(s) > 1:
            x = (s[time_col] - s[time_col].min()).dt.total_seconds()
            y = s[ma_col]
            drift = np.polyfit(x, y, 1)[0]

        return ooc_ratio, drift

    OOC_volt, drift_volt = _calc_ooc_and_drift(df, "volt", "ì „ì••ì´ë™í‰ê· ", "ì „ì••ì´ë™í‘œì¤€í¸ì°¨", "pk_datetime", k)
    OOC_amp, drift_amp = _calc_ooc_and_drift(df, "ampere", "ì „ë¥˜ì´ë™í‰ê· ", "ì „ë¥˜ì´ë™í‘œì¤€í¸ì°¨", "pk_datetime", k)
    OOC_temp, drift_temp = _calc_ooc_and_drift(df, "temperature", "ì˜¨ë„ì´ë™í‰ê· ", "ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨", "pk_datetime", k)

    summary = {
        "defect_rate": defect_rate,
        "volt_diff": volt_diff,
        "amp_diff": amp_diff,
        "temp_diff": temp_diff,
        "ISI_volt": ISI_volt,
        "DRI_current": DRI_current,
        "MSK_temp": MSK_temp,
        "OOC_volt": OOC_volt,
        "drift_volt": drift_volt,
        "OOC_amp": OOC_amp,
        "drift_amp": drift_amp,
        "OOC_temp": OOC_temp,
        "drift_temp": drift_temp,
    }

    return summary, segment_defect_rate, hourly_defect_rate


def classification_report_to_df(report_dict: dict) -> pd.DataFrame:
    df = pd.DataFrame(report_dict).T.round(3)
    if "support" in df.columns:
        df["support"] = df["support"].fillna(0).astype(int)

    preferred = ["0", "1", "accuracy", "macro avg", "weighted avg"]
    keep = [i for i in preferred if i in df.index]
    return df.loc[keep]


# =========================================================
# 3) ML Data for Dashboard (same as training pipeline basis)
# =========================================================
@st.cache_data
def make_ml_data(raw: pd.DataFrame) -> pd.DataFrame:
    mil = raw.copy()

    # ìƒì„±ì‹œê°„ / ë‘ê»˜ ê´€ë ¨
    time_diff = mil.groupby("sequence_index").agg(
        ìƒì„±ì‹œê°„=("pk_datetime", lambda x: x.max() - x.min())
    ).reset_index()

    mil = pd.merge(mil, time_diff, on="sequence_index", how="left")
    mil["ì‹œê°„ë³€í™”ëŸ‰(ì´ˆ)"] = mil["ìƒì„±ì‹œê°„"].dt.total_seconds()
    mil["ë‘ê»˜ë³€í™”ëŸ‰"] = mil["ampere"] * mil["ì‹œê°„ë³€í™”ëŸ‰(ì´ˆ)"]
    mil["ìµœì¢…ë‘ê»˜"] = mil.groupby("sequence_index")["ë‘ê»˜ë³€í™”ëŸ‰"].transform("sum")

    # ì‹œê³„ì—´ ì—”ì§€ë‹ˆì–´ë§
    mil = add_time_features(mil)

    # tertile ë¶€ì—¬
    def split_into_tertiles(group: pd.DataFrame) -> pd.DataFrame:
        n = len(group)
        group = group.sort_values("pk_datetime")
        group["tertile"] = pd.qcut(np.arange(n), 3, labels=[0, 1, 2])
        return group

    mil_tertile = mil.groupby("sequence_index").apply(split_into_tertiles).reset_index(drop=True)

    # êµ¬ê°„ë³„ í‰ê·  ì§‘ê³„
    mil_tertile = (
        mil_tertile
        .groupby(["sequence_index", "tertile"])
        .mean(numeric_only=True)
        .reset_index()
    )

    features_to_use = [
        "volt", "ampere", "temperature",
        "ampere_lag1", "volt_lag1", "temperature_lag1",
        "ì „ë¥˜ì´ë™í‰ê· ", "ì „ì••ì´ë™í‰ê· ", "ì˜¨ë„ì´ë™í‰ê· ",
        "ì „ë¥˜ì´ë™í‘œì¤€í¸ì°¨", "ì „ì••ì´ë™í‘œì¤€í¸ì°¨", "ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨",
        "â–³ì „ë¥˜", "â–³ì „ì••", "â–³ì˜¨ë„",
        "failure", "tertile",
        "ì‹œê°„ë³€í™”ëŸ‰(ì´ˆ)", "rec_num",
        "ë‘ê»˜ë³€í™”ëŸ‰", "ìµœì¢…ë‘ê»˜",
        "sequence_index"
    ]

    missing = sorted(set(features_to_use) - set(mil_tertile.columns))
    if missing:
        raise KeyError(f"make_ml_data()ì—ì„œ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing}")

    mil_tertile = mil_tertile[features_to_use].dropna()
    mil_tertile["tertile"] = mil_tertile["tertile"].astype(int)

    return mil_tertile


# =========================================================
# 4) Model + Meta
# =========================================================
@st.cache_resource
def load_model_and_meta(pkl_path="best_rf.pkl", meta_path="rf_metrics.json"):
    model = joblib.load(pkl_path)
    with open(meta_path, "r", encoding="utf-8") as f:
        meta = json.load(f)
    return model, meta


mil_ml = make_ml_data(mil_raw)
rf_model, rf_meta = load_model_and_meta()

RF_THRESHOLD = float(rf_meta.get("threshold", 0.5))

feature_names = rf_meta.get("feature_importance", {}).get("features", None)
if feature_names is None:
    feature_names = [c for c in mil_ml.columns if c != "failure"]

missing_for_X = sorted(set(feature_names) - set(mil_ml.columns))
if missing_for_X:
    raise KeyError(f"X ë§Œë“¤ ë•Œ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_for_X}")

X_all = mil_ml[feature_names].copy()
y_all = (mil_ml["failure"] == -1.0).astype(int)

X_train, X_test, y_train, y_test = train_test_split(
    X_all, y_all, test_size=0.2, stratify=y_all, random_state=42
)

feature_means = rf_meta.get("feature_means", None)
if feature_means is None:
    feature_means = X_train.mean(numeric_only=True).to_dict()

for col in feature_names:
    if col not in feature_means:
        feature_means[col] = 0.0


# =========================================================
# 5) 1-point Input â†’ RF Input Row
# =========================================================
def make_rf_input_row(
    ampere: float,
    volt: float,
    temperature: float,
    rec_num: int,
    tertile: int,
    feature_cols: list[str],
    base_means: dict
) -> pd.DataFrame:
    values = {c: float(base_means.get(c, 0.0)) for c in feature_cols}

    if "ampere" in values: values["ampere"] = float(ampere)
    if "volt" in values: values["volt"] = float(volt)
    if "temperature" in values: values["temperature"] = float(temperature)
    if "rec_num" in values: values["rec_num"] = int(rec_num)
    if "tertile" in values: values["tertile"] = int(tertile)

    if "ampere_lag1" in values: values["ampere_lag1"] = float(ampere)
    if "volt_lag1" in values: values["volt_lag1"] = float(volt)
    if "temperature_lag1" in values: values["temperature_lag1"] = float(temperature)

    if "ì „ë¥˜ì´ë™í‰ê· " in values: values["ì „ë¥˜ì´ë™í‰ê· "] = float(ampere)
    if "ì „ì••ì´ë™í‰ê· " in values: values["ì „ì••ì´ë™í‰ê· "] = float(volt)
    if "ì˜¨ë„ì´ë™í‰ê· " in values: values["ì˜¨ë„ì´ë™í‰ê· "] = float(temperature)

    if "ì „ë¥˜ì´ë™í‘œì¤€í¸ì°¨" in values: values["ì „ë¥˜ì´ë™í‘œì¤€í¸ì°¨"] = 0.0
    if "ì „ì••ì´ë™í‘œì¤€í¸ì°¨" in values: values["ì „ì••ì´ë™í‘œì¤€í¸ì°¨"] = 0.0
    if "ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨" in values: values["ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨"] = 0.0

    if "â–³ì „ë¥˜" in values: values["â–³ì „ë¥˜"] = 0.0
    if "â–³ì „ì••" in values: values["â–³ì „ì••"] = 0.0
    if "â–³ì˜¨ë„" in values: values["â–³ì˜¨ë„"] = 0.0

    return pd.DataFrame([values])[feature_cols]


# =========================================================
# 6) Range Helpers (per rec_num/tertile)
# =========================================================
def get_training_ranges(mil_ml_: pd.DataFrame, rec_num: int, tertile: int) -> dict:
    df = mil_ml_.copy()
    if "rec_num" in df.columns:
        df = df[df["rec_num"] == rec_num]
    if "tertile" in df.columns:
        df = df[df["tertile"] == tertile]
    if len(df) == 0:
        df = mil_ml_.copy()

    ranges = {}
    for col in ["ampere", "volt", "temperature"]:
        if col in df.columns:
            ranges[col] = (float(df[col].min()), float(df[col].max()))
    return ranges


def render_range_caption_under_input(value: float, mn: float, mx: float, unit: str = "") -> bool:
    if np.isnan(mn) or np.isnan(mx):
        st.caption("í•™ìŠµ ë²”ìœ„: ê³„ì‚° ë¶ˆê°€")
        return False

    out = (value < mn) or (value > mx)
    unit_str = f" {unit}" if unit else ""
    tag = " (ë²”ìœ„ ë°–)" if out else ""
    st.caption(f"í•™ìŠµ ë²”ìœ„: {mn:.2f} ~ {mx:.2f}{unit_str}{tag}")
    return out


# =========================================================
# 7) Sidebar Navigation
# =========================================================
page = st.sidebar.radio(
    "í˜ì´ì§€ ì„ íƒ",
    (
        "ğŸ“Š ê³µì • KPI",
        "ğŸ“… Sequence íŒ¨í„´ í•œëˆˆì—",
        "ğŸ’» ML ì˜ˆì¸¡",
        "ğŸ§¯ ë¶ˆëŸ‰ ì‹œí€€ìŠ¤ í•œëˆˆì—",
        "ğŸª„ ì´ìƒê°’ ì•Œë ¤ë“œë¦¼",
    ),
)


# =========================================================
# 8) Pages
# =========================================================
def page_kpi():
    st.markdown("#### ğŸ“Š ê³µì • KPI ì§€í‘œ")

    rec_options = sorted(mil_raw["rec_num"].dropna().unique())
    rec_selected = st.selectbox("rec_num ì„ íƒ", rec_options)

    mil = mil_raw[mil_raw["rec_num"] == rec_selected].copy()
    mil = add_time_features(mil)

    quality_summary, seg_defect_rate, hourly_defect_rate = compute_quality_metrics(mil, k=3.0)

    col_left, col_mid, col_right = st.columns([1, 1, 1])

    with col_left:
        st.markdown("##### ğŸ§ª í’ˆì§ˆ ì§€í‘œ")
        st.metric("ì „ì²´ ë¶ˆëŸ‰ë¥ ", f"{quality_summary['defect_rate'] * 100:.1f} %")
        st.metric("Volt í‰ê·  ì°¨ì´ (ë¶ˆëŸ‰-ì •ìƒ)", f"{quality_summary['volt_diff']:.2f}")
        st.metric("Ampere í‰ê·  ì°¨ì´ (ë¶ˆëŸ‰-ì •ìƒ)", f"{quality_summary['amp_diff']:.2f}")
        st.metric("ì˜¨ë„ í‰ê·  ì°¨ì´ (ë¶ˆëŸ‰-ì •ìƒ)", f"{quality_summary['temp_diff']:.2f}")

    with col_mid:
        st.markdown("##### ğŸ”§ ì„¼ì„œ ê¸°ë°˜ í’ˆì§ˆ ì§€í‘œ")
        ISI = quality_summary["ISI_volt"]
        st.metric("ISI_volt (ì „ì•• ë³€ë™ì„± ë¶ˆëŸ‰ ë¯¼ê°ë„)", f"{ISI:.2f}" if not np.isnan(ISI) else "N/A")
        st.metric("DRI_current (ë³€í™”ëŸ‰ ê¸°ë°˜ í’ˆì§ˆ ìœ„í—˜ì§€ìˆ˜)", f"{quality_summary['DRI_current']:.3f}")
        st.metric("MSK_temp (ì´ë™í‘œì¤€í¸ì°¨ ê¸°ë°˜ ì˜¨ë„ ë¯¼ê°ë„)", f"{quality_summary['MSK_temp']:.3f}")

    with col_right:
        st.markdown("##### ğŸ­ ê³µì • ìƒíƒœ KPI")
        st.metric("OOC_volt (ì „ì•• ì •ìƒ ì˜ì—­ ì¼íƒˆ ë¹„ìœ¨)", f"{quality_summary['OOC_volt'] * 100:.1f} %")
        st.metric("OOC_amp (ì „ë¥˜ ì •ìƒ ì˜ì—­ ì¼íƒˆ ë¹„ìœ¨)", f"{quality_summary['OOC_amp'] * 100:.1f} %")
        st.metric("OOC_temp (ì˜¨ë„ ì •ìƒ ì˜ì—­ ì¼íƒˆ ë¹„ìœ¨)", f"{quality_summary['OOC_temp'] * 100:.1f} %")

    st.markdown("---")
    st.markdown("#### ğŸ”¥ ë¶ˆëŸ‰ ë°œìƒ sequence/ë‚ ì§œ")

    seg_df = seg_defect_rate.reset_index()
    seg_df.columns = ["sequence_index", "defect_rate"]
    if not seg_df.empty:
        seg_chart = (
            alt.Chart(seg_df)
            .mark_bar(color=DEFECT_RED)
            .encode(
                x=alt.X("sequence_index:O", title="Sequence"),
                y=alt.Y("defect_rate:Q", title="ë¶ˆëŸ‰ë¥ "),
            )
            .properties(height=120)
        )
        st.altair_chart(seg_chart, use_container_width=True)

    hour_df = hourly_defect_rate.reset_index()
    hour_df.columns = ["pk_datetime", "defect_rate"]
    if not hour_df.empty:

        line = (
            alt.Chart(hour_df)
            .mark_line(color=DEFECT_RED)
            .encode(
                x=alt.X("pk_datetime:T", title="ì¼ì‹œ",
                        axis=alt.Axis(format="%m-%d %H:%M", labelAngle=-45)),
                y=alt.Y("defect_rate:Q", title="ë¶ˆëŸ‰ë¥ "),
                tooltip=[
                    alt.Tooltip("pk_datetime:T", title="ì¼ì‹œ"),
                    alt.Tooltip("defect_rate:Q", title="ë¶ˆëŸ‰ë¥ ", format=".3f"),
                ],
            )
        )

        points = (
            alt.Chart(hour_df)
            .mark_point(color=DEFECT_RED, filled=True, size=40)
            .encode(
                x="pk_datetime:T",
                y="defect_rate:Q",
                tooltip=[
                    alt.Tooltip("pk_datetime:T", title="ì¼ì‹œ"),
                    alt.Tooltip("defect_rate:Q", title="ë¶ˆëŸ‰ë¥ ", format=".3f"),
                ],
            )
        )

        st.altair_chart((line + points).properties(height=200), use_container_width=True)


def page_sequence_patterns():
    st.subheader("ğŸ“… Sequenceë³„ íŒ¨í„´ í•œëˆˆì— ë³´ê¸°")

    rec_options = sorted(mil_raw["rec_num"].dropna().unique())
    rec_selected = st.selectbox("rec_num ì„ íƒ", rec_options)

    mil = mil_raw[mil_raw["rec_num"] == rec_selected].copy()
    mil = add_time_features(mil)

    seq_status = (
        mil.groupby("sequence_index")["failure"]
        .agg(lambda s: -1 if (s == -1).any() else 1)
        .reset_index(name="seq_failure")
    )
    seq_status["status_label"] = seq_status["seq_failure"].map({-1: "âš ", 1: "âœ…"})
    seq_status["option_label"] = seq_status.apply(lambda r: f"{int(r.sequence_index)} - {r.status_label}", axis=1)

    label_to_seq = dict(zip(seq_status["option_label"], seq_status["sequence_index"]))

    options = seq_status["option_label"].tolist()
    default_vals = options[:3] if len(options) >= 3 else options

    selected_labels = st.multiselect("Sequence ì„ íƒ(âœ…ì–‘í’ˆ, âš ë¶ˆëŸ‰)", options=options, default=default_vals)
    if not selected_labels:
        st.info("ìµœì†Œ 1ê°œ ì´ìƒì˜ ì‹œí€€ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        st.stop()

    selected_seqs = [label_to_seq[l] for l in selected_labels]
    mil_sel = mil[mil["sequence_index"].isin(selected_seqs)].copy()
    mil_sel = mil_sel.sort_values(["sequence_index", "pk_datetime"])

    mil_sel["t_min"] = mil_sel.groupby("sequence_index")["pk_datetime"].transform("min")
    mil_sel["t_max"] = mil_sel.groupby("sequence_index")["pk_datetime"].transform("max")

    dt = (mil_sel["pk_datetime"] - mil_sel["t_min"]).dt.total_seconds()
    total = (mil_sel["t_max"] - mil_sel["t_min"]).dt.total_seconds().replace(0, 1)
    mil_sel["norm_time"] = dt / total

    st.caption("â€» xì¶•ì€ ê° ì‹œí€€ìŠ¤ì˜ ì‹œì‘-ëì„ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”í•œ ìƒëŒ€ ì‹œê°„ì…ë‹ˆë‹¤.")

    charts = []
    for sensor in ["ampere", "volt", "temperature"]:
        df_s = mil_sel[["sequence_index", "norm_time", sensor]].copy()
        chart = (
            alt.Chart(df_s)
            .mark_line()
            .encode(
                x=alt.X("norm_time:Q", title=""),
                y=alt.Y(f"{sensor}:Q", title=sensor),
                color=alt.Color(
                    "sequence_index:N",
                    title="Sequence",
                    scale=alt.Scale(scheme="tableau10")  # âœ… ê¸°ë³¸ íŒŒë‘ ë‹¨ì¼ìƒ‰ ì œê±°
                ),
                tooltip=[
                    alt.Tooltip("sequence_index:N", title="Sequence"),
                    alt.Tooltip("norm_time:Q", title="ì‹œê°„(0~1)", format=".2f"),
                    alt.Tooltip(f"{sensor}:Q", title=sensor, format=".2f"),
                ],
            )
            .properties(height=220)
        )
        charts.append(chart)

    combined = alt.vconcat(*charts).resolve_scale(y="independent")
    st.altair_chart(combined, use_container_width=True)


def page_ml_results():
    st.subheader("ğŸ’» ML ì˜ˆì¸¡")

    y_proba = rf_model.predict_proba(X_test[feature_names])[:, 1]
    y_proba_s = pd.Series(y_proba, index=y_test.index)

    col_left, col_gap, col_right = st.columns([1, 0.2, 1])

    with col_right:
        st.markdown("#### ğŸ§® ì„ê³„ê°’ & í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ")

        default_th = float(st.session_state.get("user_th", RF_THRESHOLD))
        user_th = st.slider("Threshold (ë¶ˆëŸ‰ìœ¼ë¡œ ì˜ˆì¸¡í•  ìµœì†Œ í™•ë¥ )", 0.0, 1.0, value=default_th, step=0.01, key="th_slider_ml")
        st.session_state["user_th"] = float(user_th)

        y_pred_user = (y_proba_s >= user_th).astype(int)

        report_dict = classification_report(y_test, y_pred_user, output_dict=True, zero_division=0)
        acc = report_dict["accuracy"]
        f1_defect = report_dict.get("1", {}).get("f1-score", 0.0)
        recall_defect = report_dict.get("1", {}).get("recall", 0.0)

        m1, m2, m3 = st.columns(3)
        m1.metric("Accuracy", f"{acc*100:.1f} %")
        m2.metric("F1 (ë¶ˆëŸ‰)", f"{f1_defect:.3f}")
        m3.metric("Recall (ë¶ˆëŸ‰)", f"{recall_defect:.3f}")

        st.caption("ğŸ“„ ì „ì²´ ë¶„ë¥˜ ë¦¬í¬íŠ¸")
        st.dataframe(classification_report_to_df(report_dict), use_container_width=True, hide_index=False)

    with col_gap:
        st.subheader("")

    with col_left:
        st.markdown("#### ğŸªŸ Confusion Matrix")
        cm = confusion_matrix(y_test, y_pred_user)

        cm_df = pd.DataFrame(cm, index=["Actual 0", "Actual 1"], columns=["Pred 0", "Pred 1"]).reset_index().rename(columns={"index": "actual"})
        cm_long = cm_df.melt(id_vars="actual", var_name="predicted", value_name="count")

        heatmap = (
            alt.Chart(cm_long)
            .mark_rect()
            .encode(
                x=alt.X("predicted:N", title="Predicted"),
                y=alt.Y("actual:N", title="Actual"),
                color=alt.Color("count:Q", scale=alt.Scale(scheme="reds"), legend=alt.Legend(title="Count")),
                tooltip=[
                    alt.Tooltip("actual:N", title="Actual"),
                    alt.Tooltip("predicted:N", title="Predicted"),
                    alt.Tooltip("count:Q", title="Count"),
                ],
            )
            .properties(height=500)
        )

        text = (
            alt.Chart(cm_long)
            .mark_text(fontSize=14, fontWeight="bold", color="black")
            .encode(x="predicted:N", y="actual:N", text="count:Q")
        )

        st.altair_chart(heatmap + text, use_container_width=True)

    st.markdown("#### ğŸ“Š Feature Importance")
    fi = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)

    fi_df = pd.DataFrame({"feature": fi.index, "importance": fi.values})
    fi_chart = (
        alt.Chart(fi_df)
        .mark_bar(color="#C0392B")  
        .encode(
            x=alt.X("feature:N", sort="-y", axis=alt.Axis(labelAngle=-45, title="Feature")),
            y=alt.Y("importance:Q", title="Importance"),
            tooltip=[
                alt.Tooltip("feature:N", title="Feature"),
                alt.Tooltip("importance:Q", title="Importance", format=".4f"),
            ],
        )
        .properties(height=350))
    st.altair_chart(fi_chart, use_container_width=True)


def page_fault_sequences():
    st.subheader("ğŸ§¯ ë¶ˆëŸ‰ ì‹œí€€ìŠ¤ í•œëˆˆì— ë³´ê¸°")

    th_default = float(st.session_state.get("user_th", RF_THRESHOLD))
    user_th = st.slider("Threshold (ë¶ˆëŸ‰ìœ¼ë¡œ ì˜ˆì¸¡í•  ìµœì†Œ í™•ë¥ )", 0.0, 1.0, value=th_default, step=0.01, key="th_slider_fault")
    st.session_state["user_th"] = float(user_th)

    y_proba_test = rf_model.predict_proba(X_test[feature_names])[:, 1]
    y_proba_s = pd.Series(y_proba_test, index=y_test.index)
    y_pred_user = (y_proba_s >= user_th).astype(int)

    # all data -> seq average proba
    proba_all = rf_model.predict_proba(X_all[feature_names])[:, 1]
    mil_all = mil_ml.copy()
    mil_all["proba_fail"] = proba_all

    seq_prob_all = (
        mil_all.groupby("sequence_index")
        .agg(
            mean_proba=("proba_fail", "mean"),
            failure_seq=("failure", lambda s: -1.0 if (s == -1.0).any() else 1.0),
        )
        .reset_index()
    )
    seq_prob_all["pred_seq"] = (seq_prob_all["mean_proba"] >= user_th).astype(int)
    bad_seq_df = seq_prob_all[seq_prob_all["pred_seq"] == 1].sort_values("mean_proba", ascending=False)

    col_left, col_right = st.columns([1, 1])

    with col_left:
        st.markdown("#### ğŸ” ì‹œí€€ìŠ¤ë³„ ë¶ˆëŸ‰ í™•ë¥ ")
        seq_list = sorted(mil_ml["sequence_index"].unique())
        seq_choice = st.selectbox("ì‹œí€€ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”", seq_list, key="seq_choice_fault")

        seq_df = mil_ml[mil_ml["sequence_index"] == seq_choice]
        if len(seq_df) > 0:
            proba_seq = rf_model.predict_proba(seq_df[feature_names])[:, 1]
            mean_proba = float(np.mean(proba_seq))
            pred_seq = int(mean_proba >= user_th)

            c1, c2, c3 = st.columns(3)
            c1.metric("í‰ê·  ë¶ˆëŸ‰ í™•ë¥ ", f"{mean_proba:.3f}")
            c2.metric("ì„ê³„ê°’", f"{user_th:.3f}")
            c3.metric("ì˜ˆì¸¡ ê²°ê³¼", "âš " if pred_seq == 1 else "âœ…")

            with st.expander("ì„ íƒ ì‹œí€€ìŠ¤ (ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜) ìƒì„¸ ë³´ê¸°", expanded=False):
                seq_view = seq_df.copy()
                seq_view["ë¶ˆëŸ‰í™•ë¥ (ëª¨ë¸)"] = proba_seq
                st.dataframe(seq_view, use_container_width=True)
        else:
            st.info("í•´ë‹¹ ì‹œí€€ìŠ¤ ë°ì´í„° ì—†ìŒ")

    with col_right:
        st.markdown("#### âŒ ì˜¤ì§„(ì˜ˆì¸¡ í‹€ë¦°) ì¼€ì´ìŠ¤")
        wrong_mask = (y_test != y_pred_user)
        wrong_idx = y_test.index[wrong_mask]

        if len(wrong_idx) == 0:
            st.success("í˜„ì¬ ì˜¤ì§„ ì¼€ì´ìŠ¤ ì—†ìŒ")
        else:
            st.write(f"ì´ **{len(wrong_idx)}ê±´**ì˜ ì˜¤ì§„ ì¼€ì´ìŠ¤")
            with st.expander("ì˜¤ì§„ ì¼€ì´ìŠ¤ ìƒì„¸ ë³´ê¸°", expanded=False):
                wrong_cases = mil_ml.loc[wrong_idx].copy()
                wrong_cases["ì‹¤ì œê°’(y_true)"] = y_test.loc[wrong_idx]
                wrong_cases["ì˜ˆì¸¡ê°’(y_pred)"] = y_pred_user.loc[wrong_idx]
                wrong_cases["ë¶ˆëŸ‰í™•ë¥ (ëª¨ë¸)"] = y_proba_s.loc[wrong_idx]
                st.dataframe(wrong_cases, use_container_width=True)

    st.markdown("---")
    st.markdown("#### ğŸ“Š ë¶ˆëŸ‰ìœ¼ë¡œ ì˜ˆì¸¡ëœ ì‹œí€€ìŠ¤ ì „ì²´ ë³´ê¸°")
    st.write(f"í˜„ì¬ ì„ê³„ê°’ ê¸°ì¤€ìœ¼ë¡œ ë¶ˆëŸ‰ìœ¼ë¡œ ì˜ˆì¸¡ëœ ì‹œí€€ìŠ¤ëŠ” ì´ **{len(bad_seq_df)}ê°œ** ì…ë‹ˆë‹¤.")

    if len(bad_seq_df) == 0:
        st.info("ì´ ì„ê³„ê°’ì—ì„œëŠ” ë¶ˆëŸ‰ìœ¼ë¡œ ì˜ˆì¸¡ëœ ì‹œí€€ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    chart_df = bad_seq_df.copy()
    chart_df["sequence_index"] = chart_df["sequence_index"].astype(str)
    chart_df["ì‹¤ì œë¼ë²¨"] = np.where(chart_df["failure_seq"] == -1.0, "ì‹¤ì œ ë¶ˆëŸ‰", "ì‹¤ì œ ì–‘í’ˆ")

    bad_chart = (
        alt.Chart(chart_df)
        .mark_bar()
        .encode(
            x=alt.X("sequence_index:N", sort="-y", title="Sequence Index"),
            y=alt.Y("mean_proba:Q", title="í‰ê·  ë¶ˆëŸ‰ ì˜ˆì¸¡ í™•ë¥ "),
            color=alt.Color(
                "ì‹¤ì œë¼ë²¨:N",
                scale=alt.Scale(
                    domain=["ì‹¤ì œ ë¶ˆëŸ‰", "ì‹¤ì œ ì–‘í’ˆ"],
                    range=[DEFECT_RED, OK_GRAY]
                ),
                legend=alt.Legend(title="ì‹¤ì œ ë¼ë²¨")
            ),
            tooltip=[
                alt.Tooltip("sequence_index:N", title="Sequence"),
                alt.Tooltip("mean_proba:Q", title="í‰ê·  ë¶ˆëŸ‰ í™•ë¥ ", format=".3f"),
                alt.Tooltip("ì‹¤ì œë¼ë²¨:N", title="ì‹¤ì œ ë¼ë²¨"),
            ],
        )
        .properties(height=300)
    )

    # âœ… ê·¸ë˜í”„/í…Œì´ë¸” ì¶œë ¥ (ì—¬ê¸°ê°€ ë¹ ì§€ë©´ í™”ë©´ì— ì•ˆ ë‚˜ì˜´)
   
    st.altair_chart(bad_chart, use_container_width=True)


def page_point_predict():
    st.subheader("ğŸª„ ì´ìƒê°’ ì•Œë ¤ë“œë¦¼")
    st.caption(
        "ì •ë¥˜ê¸°(rec_num), ê³µì • êµ¬ê°„(tertile), ì˜¨ë„Â·ì „ë¥˜Â·ì „ì•• 1í¬ì¸íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ "
        "ê¸°ì¡´ RandomForest ëª¨ë¸ë¡œ ì´ ì¡°ê±´ì´ ì–‘í’ˆ/ë¶ˆëŸ‰ ë¶„í¬ ì¤‘ ì–´ë””ì— ê°€ê¹Œìš´ì§€ íŒì •í•©ë‹ˆë‹¤."
    )

    col_left, col_right = st.columns([2, 3])

    with col_left:
        st.markdown("#### ì…ë ¥ ì¡°ê±´")

        rec_label = st.selectbox("ì •ë¥˜ê¸°(rec_num)", options=["rec1", "rec2"])
        rec_num_input = 1 if rec_label == "rec1" else 2

        tertile_label = st.selectbox(
            "ê³µì • ë‚´ ìœ„ì¹˜ (tertile)",
            options=["Ramp-up(0)", "Plateau(1)", "Ramp-down(2)"]
        )
        if "0" in tertile_label:
            tertile_input = 0
        elif "1" in tertile_label:
            tertile_input = 1
        else:
            tertile_input = 2

        ranges = get_training_ranges(mil_ml, rec_num=rec_num_input, tertile=tertile_input)
        (a_min, a_max) = ranges.get("ampere", (np.nan, np.nan))
        (v_min, v_max) = ranges.get("volt", (np.nan, np.nan))
        (t_min, t_max) = ranges.get("temperature", (np.nan, np.nan))

        ampere_input = st.number_input("ì „ë¥˜ (ampere)", value=551.5, step=0.1, format="%.2f")
        ood_a = render_range_caption_under_input(ampere_input, a_min, a_max)

        volt_input = st.number_input("ì „ì•• (volt)", value=23.2, step=0.1, format="%.2f")
        ood_v = render_range_caption_under_input(volt_input, v_min, v_max)

        temp_input = st.number_input("ì˜¨ë„ (â„ƒ)", value=12.4, step=0.1, format="%.2f")
        ood_t = render_range_caption_under_input(temp_input, t_min, t_max, unit="â„ƒ")

        is_ood = bool(ood_a or ood_v or ood_t)

        st.markdown("")
        run_button = st.button("ì´ ì¡°ê±´ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê¸°", type="primary")

    with col_right:
        if not run_button:
            st.info("ì¢Œì¸¡ì—ì„œ ì¡°ê±´ì„ ì…ë ¥í•œ í›„ **[ì´ ì¡°ê±´ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê¸°]** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
            return

        if is_ood:
            st.error("ì…ë ¥ê°’ì´ í•™ìŠµ ë°ì´í„° ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤. (OOD) ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ì•„ ì‹¤í–‰ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        X_input = make_rf_input_row(
            ampere=ampere_input,
            volt=volt_input,
            temperature=temp_input,
            rec_num=rec_num_input,
            tertile=tertile_input,
            feature_cols=feature_names,
            base_means=feature_means
        )

        proba_bad = float(rf_model.predict_proba(X_input)[0, 1])
        pred = int(proba_bad >= RF_THRESHOLD)
        label_text = "ë¶ˆëŸ‰" if pred == 1 else "ì •ìƒ"

        st.markdown("#### ì˜ˆì¸¡ ê²°ê³¼")
        m1, m2 = st.columns(2)
        m1.metric("íŒì • ë¼ë²¨", label_text)
        m2.metric("ë¶ˆëŸ‰ í™•ë¥ ", f"{proba_bad * 100:.1f} %")

        # âœ… st.bar_chart(ê¸°ë³¸ íŒŒë‘) ëŒ€ì‹  Altairë¡œ ìƒ‰ ê³ ì •
        prob_plot_df = pd.DataFrame({
            "label": ["ì •ìƒ", "ë¶ˆëŸ‰"],
            "prob": [1 - proba_bad, proba_bad]
        })
        prob_chart = (
            alt.Chart(prob_plot_df)
            .mark_bar()
            .encode(
                x=alt.X("label:N", title=""),
                y=alt.Y("prob:Q", title="í™•ë¥ ", axis=alt.Axis(format="%")),
                color=alt.Color(
                    "label:N",
                    scale=alt.Scale(domain=["ì •ìƒ", "ë¶ˆëŸ‰"], range=[OK_GRAY, DEFECT_RED]),
                    legend=None
                ),
                tooltip=[
                    alt.Tooltip("label:N", title="ë¼ë²¨"),
                    alt.Tooltip("prob:Q", title="í™•ë¥ ", format=".3f"),
                ]
            )
            .properties(height=240)
        )
        st.altair_chart(prob_chart, use_container_width=True)

        st.markdown("---")
        if pred == 1:
            st.warning(
                f"ì´ ì¡°ê±´ì€ ë¶ˆëŸ‰ í™•ë¥ ì´ **{proba_bad:.2f}**ë¡œ "
                f"ì„ê³„ê°’({RF_THRESHOLD:.2f})ì„ ì´ˆê³¼í•˜ì—¬ **ë¶ˆëŸ‰ ë¶„í¬**ì— ë” ê°€ê¹ìŠµë‹ˆë‹¤."
            )
        else:
            st.success(
                f"ì´ ì¡°ê±´ì€ ë¶ˆëŸ‰ í™•ë¥ ì´ **{proba_bad:.2f}**ë¡œ "
                f"ì„ê³„ê°’({RF_THRESHOLD:.2f})ë³´ë‹¤ ë‚®ì•„ **ì •ìƒ ë¶„í¬**ì— ë” ê°€ê¹ìŠµë‹ˆë‹¤."
            )


# =========================================================
# 9) Router
# =========================================================
if page == "ğŸ“Š ê³µì • KPI":
    page_kpi()
elif page == "ğŸ“… Sequence íŒ¨í„´ í•œëˆˆì—":
    page_sequence_patterns()
elif page == "ğŸ’» ML ì˜ˆì¸¡":
    page_ml_results()
elif page == "ğŸ§¯ ë¶ˆëŸ‰ ì‹œí€€ìŠ¤ í•œëˆˆì—":
    page_fault_sequences()
elif page == "ğŸª„ ì´ìƒê°’ ì•Œë ¤ë“œë¦¼":
    page_point_predict()
