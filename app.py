import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import altair as alt
import joblib
import json

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

#==========================
# 0. í˜ì´ì§€ ëª… ì„¤ì • ë° ì‚¬ì´ë“œë°” ë””ìì¸
#==========================
st.set_page_config(page_title="ê·¸ ì´ë¦„ë„ ë¬´ì‹œë¬´ì‹œí•œ ë°€ìŠ¤í™ 2.0", layout='wide')

st.markdown("""
<style>

/* ğŸ”¹ ë¼ë””ì˜¤ ê·¸ë£¹ ì „ì²´ ê°„ê²© */
section[data-testid="stSidebar"] div[role="radiogroup"] {
    display: flex;
    flex-direction: column;
    gap: 0.5rem;   /* ì¹´ë“œ ì‚¬ì´ ê°„ê²© */
}

/* ğŸ”¹ ê° ë¼ë””ì˜¤ í•­ëª©ì„ ì¹´ë“œì²˜ëŸ¼ ë³´ì´ë„ë¡ ë³€í˜• */
section[data-testid="stSidebar"] div[role="radiogroup"] > label {
    background-color: #ffffff;
    padding: 12px 16px;
    border-radius: 10px;
    border: 1px solid #d0d4dd;
    cursor: pointer;
    transition: all 0.15s ease;
    box-shadow: 0px 1px 2px rgba(0,0,0,0.08);
}

/* ğŸ”¹ ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ë©´ ì…ì²´ê° */
section[data-testid="stSidebar"] div[role="radiogroup"] > label:hover {
    background-color: #f5f7ff;
    border-color: #a5b4fc;
    box-shadow: 0px 2px 6px rgba(0,0,0,0.12);
}

/* ğŸ”¹ ì„ íƒëœ í•­ëª© ê°•ì¡° */
section[data-testid="stSidebar"] div[role="radiogroup"] > label[data-selected="true"] {
    background-color: #eef2ff;
    border: 2px solid #6366f1;
    box-shadow: 0px 2px 6px rgba(99, 102, 241, 0.25);
}

/* ğŸ”¹ í…ìŠ¤íŠ¸ ì¡°ê¸ˆ í‚¤ìš´ë‹¤ */
section[data-testid="stSidebar"] div[role="radiogroup"] span {
    font-size: 16px !important;
    font-weight: 600 !important;
}

</style>
""", unsafe_allow_html=True)

st.caption("ëŒ€ì‹œë³´ë“œ í”„ë¡œì íŠ¸")
st.title("ì–‘ê·¹ ì‚°í™” í”¼ë§‰ ë°ì´í„° ê¸°ë°˜ ë¶ˆëŸ‰ ì˜ˆì¸¡ ë¶„ì„")

# ===================================
# 1. ë°ì´í„° ë¡œë“œ
# ===================================
@st.cache_data
def load_data():
    mil = pd.read_csv('ë°©ì‚°í†µí•©ë°ì´í„°ì…‹.csv')
    mil['pk_datetime'] = pd.to_datetime(mil['pk_datetime'])
    return mil

mil_raw = load_data()   # ì›ë³¸

# ===================================
# 2. ê³µí†µ í•¨ìˆ˜ë“¤
# ===================================
def add_time_features(mil: pd.DataFrame) -> pd.DataFrame:
    mil = mil.sort_values(["sequence_index", "pk_datetime"]).copy()

    # lag
    mil['ampere_lag1']      = mil.groupby('sequence_index')['ampere'].shift(1)
    mil['volt_lag1']        = mil.groupby('sequence_index')['volt'].shift(1)
    mil['temperature_lag1'] = mil.groupby('sequence_index')['temperature'].shift(1)

    # rolling mean / std (window=3, shift 1)
    mil['ì „ë¥˜ì´ë™í‰ê· '] = (
        mil.groupby('sequence_index')['ampere']
           .rolling(window=3).mean().shift(1)
           .reset_index(level=0, drop=True)
    )
    mil['ì „ì••ì´ë™í‰ê· '] = (
        mil.groupby('sequence_index')['volt']
           .rolling(window=3).mean().shift(1)
           .reset_index(level=0, drop=True)
    )
    mil['ì˜¨ë„ì´ë™í‰ê· '] = (
        mil.groupby('sequence_index')['temperature']
           .rolling(window=3).mean().shift(1)
           .reset_index(level=0, drop=True)
    )

    mil['ì „ë¥˜ì´ë™í‘œì¤€í¸ì°¨'] = (
        mil.groupby('sequence_index')['ampere']
           .rolling(window=3).std().shift(1)
           .reset_index(level=0, drop=True)
    )
    mil['ì „ì••ì´ë™í‘œì¤€í¸ì°¨'] = (
        mil.groupby('sequence_index')['volt']
           .rolling(window=3).std().shift(1)
           .reset_index(level=0, drop=True)
    )
    mil['ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨'] = (
        mil.groupby('sequence_index')['temperature']
           .rolling(window=3).std().shift(1)
           .reset_index(level=0, drop=True)
    )

    # diff (sequence ë³„)
    mil['â–³ì „ë¥˜'] = mil.groupby('sequence_index')['ampere'].diff()
    mil['â–³ì „ì••'] = mil.groupby('sequence_index')['volt'].diff()
    mil['â–³ì˜¨ë„'] = mil.groupby('sequence_index')['temperature'].diff()

    return mil


def compute_quality_metrics(mil: pd.DataFrame, k: float = 3.0):
    df = mil.copy()

    # failure: 1=ì •ìƒ, -1=ë¶ˆëŸ‰
    df["is_defect"] = (df["failure"] == -1).astype(int)

    # 1) ì „ì²´ ë¶ˆëŸ‰ë¥ 
    defect_rate = df["is_defect"].mean()

    # 2) sequenceë³„ ë¶ˆëŸ‰ë¥ 
    segment_defect_rate = (
        df.groupby("sequence_index")["is_defect"].mean()
    )

    # 3) ì‹œê°„ëŒ€ë³„ ë¶ˆëŸ‰ë¥  (1H)
    df_time = df.set_index("pk_datetime")
    hourly_defect_rate = df_time["is_defect"].resample("1H").mean()

    # 4) ì„¼ì„œ í‰ê·  ì°¨ì´ (ë¶ˆëŸ‰ - ì •ìƒ)
    mask_def = df["is_defect"] == 1
    mask_ok  = df["is_defect"] == 0

    volt_diff = df.loc[mask_def, "volt"].mean()        - df.loc[mask_ok, "volt"].mean()
    amp_diff  = df.loc[mask_def, "ampere"].mean()      - df.loc[mask_ok, "ampere"].mean()
    temp_diff = df.loc[mask_def, "temperature"].mean() - df.loc[mask_ok, "temperature"].mean()

    # 5) ISI_volt
    volt_std_def = df.loc[mask_def, "volt"].std()
    volt_std_ok  = df.loc[mask_ok, "volt"].std()
    ISI_volt = np.nan
    if volt_std_ok not in [0, np.nan]:
        ISI_volt = volt_std_def / volt_std_ok

    # 6) DRI_current
    DRI_current = df.loc[mask_def, "â–³ì „ë¥˜"].abs().mean()

    # 7) MSK_temp
    MSK_temp = df.loc[mask_def, "ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨"].mean()

    # 8) OOC_volt
    df["volt_dev"]   = (df["volt"] - df["ì „ì••ì´ë™í‰ê· "]).abs()
    df["volt_limit"] = k * df["ì „ì••ì´ë™í‘œì¤€í¸ì°¨"]
    df["is_ooc_volt"] = df["volt_dev"] > df["volt_limit"]
    OOC_volt = df["is_ooc_volt"].mean()

    # 9) drift_volt
    drift_volt = np.nan
    s = df[["pk_datetime", "ì „ì••ì´ë™í‰ê· "]].dropna().sort_values("pk_datetime")
    if len(s) > 1:
        x = (s["pk_datetime"] - s["pk_datetime"].min()).dt.total_seconds()
        y = s["ì „ì••ì´ë™í‰ê· "]
        drift_volt = np.polyfit(x, y, 1)[0]

    summary = {
        "defect_rate": defect_rate,
        "volt_diff": volt_diff,
        "amp_diff": amp_diff,
        "temp_diff": temp_diff,
        "ISI_volt": ISI_volt,
        "DRI_current": DRI_current,
        "MSK_temp": MSK_temp,
        "OOC_volt": OOC_volt,
        "drift_volt": drift_volt,
    }

    return summary, segment_defect_rate, hourly_defect_rate


def classification_report_to_df(report_dict):
    """
    sklearn classification_report(output_dict=True)ì„
    DataFrame í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ í‘œ í˜•íƒœ ì‹œê°í™”ì— ì í•©í•˜ê²Œ ë§Œë“ ë‹¤.
    """
    df = pd.DataFrame(report_dict).transpose()
    df = df.round(3)

    # support ê°’ì´ floatë¡œ ë‚˜ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ intë¡œ ì •ë¦¬
    if "support" in df.columns:
        df["support"] = df["support"].astype(int)

    # í–‰ ìˆœì„œë¥¼ ì‚¬ëŒì´ ë³´ê¸° ì¢‹ê²Œ ì¬ë°°ì¹˜
    preferred_index = ["0", "1", "accuracy", "macro avg", "weighted avg"]
    df = df.loc[preferred_index]

    return df


# ---------------- ML ìš© ë°ì´í„° & ëª¨ë¸ ----------------
@st.cache_data
def make_ml_data():
    # 1) ì›ë³¸ ë¡œë“œ + pk_datetime ì²˜ë¦¬
    mil = pd.read_csv("ë°©ì‚°í†µí•©ë°ì´í„°ì…‹.csv")
    mil["pk_datetime"] = pd.to_datetime(mil["pk_datetime"], errors="coerce")
    mil.dropna(subset=["pk_datetime"], inplace=True)

    # 2) ì‹œí€€ìŠ¤ë³„ ìƒì„±ì‹œê°„ / ë‘ê»˜ ê´€ë ¨ íŒŒìƒë³€ìˆ˜
    time_diff = mil.groupby('sequence_index').agg(
        ìƒì„±ì‹œê°„=('pk_datetime', lambda x: x.max() - x.min())
    ).reset_index()

    mil = pd.merge(mil, time_diff, on='sequence_index', how='left')
    mil['ì‹œê°„ë³€í™”ëŸ‰(ì´ˆ)'] = mil['ìƒì„±ì‹œê°„'].dt.total_seconds()
    mil['ë‘ê»˜ë³€í™”ëŸ‰'] = mil['ampere'] * mil['ì‹œê°„ë³€í™”ëŸ‰(ì´ˆ)']
    mil['ìµœì¢…ë‘ê»˜'] = mil.groupby('sequence_index')['ë‘ê»˜ë³€í™”ëŸ‰'].transform('sum')

    # 3) ì‹œê³„ì—´ ì—”ì§€ë‹ˆì–´ë§
    mil = add_time_features(mil)

    # 4) 3êµ¬ê°„ tertile ë¶„í• 
    sequence_area = mil.groupby('sequence_index')

    def split_into_tertiles(group):
        n = len(group)
        group = group.sort_index()  # ì‹œê°„ ìˆœ ì •ë ¬
        group['tertile'] = pd.qcut(np.arange(n), 3, labels=[0, 1, 2])
        return group

    mil_tertile = sequence_area.apply(split_into_tertiles).reset_index(drop=True)

    # 5) êµ¬ê°„ë³„ ì§‘ê³„ (í‰ê· )
    mil_tertile = (
        mil_tertile
        .groupby(['sequence_index', 'tertile'])
        .mean()
        .reset_index()
    )

    features_to_use = [
        'volt','ampere','temperature','ampere_lag1',
        'volt_lag1','temperature_lag1','ì „ë¥˜ì´ë™í‰ê· ','ì „ì••ì´ë™í‰ê· ','ì˜¨ë„ì´ë™í‰ê· ',
        'ì „ë¥˜ì´ë™í‘œì¤€í¸ì°¨','ì „ì••ì´ë™í‘œì¤€í¸ì°¨','ì˜¨ë„ì´ë™í‘œì¤€í¸ì°¨',
        'â–³ì „ë¥˜','â–³ì „ì••','â–³ì˜¨ë„',
        'failure','tertile',
        'ì‹œê°„ë³€í™”ëŸ‰(ì´ˆ)', 'rec_num',
        'ë‘ê»˜ë³€í™”ëŸ‰', 'ìµœì¢…ë‘ê»˜',
        'sequence_index'
    ]

    missing = set(features_to_use) - set(mil_tertile.columns)
    if missing:
        raise KeyError(f"make_ml_data()ì—ì„œ ëˆ„ë½ëœ ì»¬ëŸ¼: {sorted(missing)}")

    mil_tertile = mil_tertile[features_to_use].dropna()

    return mil_tertile


@st.cache_resource
def load_rf_model():
    model = joblib.load("best_rf.pkl")
    with open("rf_metrics.json", "r", encoding="utf-8") as f:
        meta = json.load(f)
    return model, meta

mil_ml = make_ml_data()
rf_model, rf_meta = load_rf_model()

threshold = float(rf_meta["threshold"])

if "feature_importance" in rf_meta and "features" in rf_meta["feature_importance"]:
    feature_names = rf_meta["feature_importance"]["features"]
else:
    feature_names = list(mil_ml.drop(columns=["failure"]).columns)

missing_for_X = set(feature_names) - set(mil_ml.columns)
if missing_for_X:
    raise KeyError(f"X ë§Œë“¤ ë•Œ ëˆ„ë½ëœ ì»¬ëŸ¼: {sorted(missing_for_X)}")

X = mil_ml[feature_names]
y = (mil_ml["failure"] == -1.0).astype(int)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ===================================
# 3. í˜ì´ì§€ ì„ íƒ (ì‚¬ì´ë“œë°”)
# ===================================
page = st.sidebar.radio(
    "í˜ì´ì§€ ì„ íƒ",
    (
        "ğŸ“Š ê³µì • KPI",
        "ğŸ“… Sequence íŒ¨í„´ í•œëˆˆì—",
        "ğŸ’» ML ì˜ˆì¸¡ ê²°ê³¼",
        "ë¶ˆëŸ‰ ì›ì¸ ë¶„ì„",
    )
)

# ===================================
# 4. í˜ì´ì§€ë³„ ë‚´ìš©
# ===================================

# ===================================
# 4-1. ê³µì • KPI
# ===================================
if page == "ğŸ“Š ê³µì • KPI":
    st.markdown("### 1. Featuring ê¸°ë°˜ KPI")
    st.markdown("#### â‘  ê³µì • KPI ì§€í‘œ")

    # rec_num í•„í„°
    rec_options = sorted(mil_raw["rec_num"].unique())
    rec_selected = st.selectbox("rec_num ì„ íƒ", rec_options)

    mil = mil_raw[mil_raw["rec_num"] == rec_selected].copy()

    mil = add_time_features(mil)
    quality_summary, seg_defect_rate, hourly_defect_rate = \
        compute_quality_metrics(mil, k=3.0)

    col_left, col_mid, col_right = st.columns([1, 1, 1])

    with col_left:
        st.markdown("##### ğŸ§ª í’ˆì§ˆ ì§€í‘œ")
        st.metric("ì „ì²´ ë¶ˆëŸ‰ë¥ ", f"{quality_summary['defect_rate'] * 100:.1f} %")
        st.metric("Volt í‰ê·  ì°¨ì´ (ë¶ˆëŸ‰-ì •ìƒ)", f"{quality_summary['volt_diff']:.2f}")
        st.metric("Ampere í‰ê·  ì°¨ì´ (ë¶ˆëŸ‰-ì •ìƒ)", f"{quality_summary['amp_diff']:.2f}")
        st.metric("ì˜¨ë„ í‰ê·  ì°¨ì´ (ë¶ˆëŸ‰-ì •ìƒ)", f"{quality_summary['temp_diff']:.2f}")

    with col_mid:
        st.markdown("##### ğŸ”§ ì„¼ì„œ ê¸°ë°˜ í’ˆì§ˆ ì§€í‘œ")
        ISI = quality_summary["ISI_volt"]
        st.metric(
            "ISI_volt (ì „ì•• ë³€ë™ì„± ë¶ˆëŸ‰ ë¯¼ê°ë„)",
            f"{ISI:.2f}" if not np.isnan(ISI) else "N/A"
        )
        st.metric("DRI_current (ë³€í™”ëŸ‰ ê¸°ë°˜ í’ˆì§ˆ ìœ„í—˜ì§€ìˆ˜)",
                  f"{quality_summary['DRI_current']:.3f}")
        st.metric("MSK_temp (ì´ë™í‘œì¤€í¸ì°¨ ê¸°ë°˜ ì˜¨ë„ ë¯¼ê°ë„)",
                  f"{quality_summary['MSK_temp']:.3f}")

    with col_right:
        st.markdown("##### ğŸ­ ê³µì • ìƒíƒœ KPI")
        st.metric(
            "OOC_volt (ì •ìƒ ì˜ì—­ ì¼íƒˆ ë¹„ìœ¨)",
            f"{quality_summary['OOC_volt'] * 100:.1f} %"
        )
        drift = quality_summary["drift_volt"]
        st.metric(
            "drift_volt (ì „ì•• DRIFT KPI)",
            f"{drift:.4f}" if not np.isnan(drift) else "N/A"
        )

    st.markdown("---")
    st.subheader("â‘¡ ë¶ˆëŸ‰ë¥  í•œëˆˆì—")

    seg_df = seg_defect_rate.reset_index()
    seg_df.columns = ["sequence_index", "defect_rate"]
    if not seg_df.empty:
        seg_chart = (
            alt.Chart(seg_df)
            .mark_bar()
            .encode(
                x=alt.X("sequence_index:O", title="Sequence"),
                y=alt.Y("defect_rate:Q", title="ë¶ˆëŸ‰ë¥ "),
            )
            .properties(height=120)
        )
        st.altair_chart(seg_chart, use_container_width=True)

    hour_df = hourly_defect_rate.reset_index()
    hour_df.columns = ["pk_datetime", "defect_rate"]
    if not hour_df.empty:
        hour_chart = (
            alt.Chart(hour_df)
            .mark_line(point=True)
            .encode(
                x=alt.X("pk_datetime:T",
                        title="ì¼ì‹œ",
                        axis=alt.Axis(format="%m-%d %H:%M", labelAngle=-45)),
                y=alt.Y("defect_rate:Q", title="ë¶ˆëŸ‰ë¥ "),
            )
            .properties(height=200)
        )
        st.altair_chart(hour_chart, use_container_width=True)


# ===================================
# 4-2. Sequence íŒ¨í„´ í•œëˆˆì—
# ===================================
elif page == "ğŸ“… Sequence íŒ¨í„´ í•œëˆˆì—":
    st.subheader("ğŸ“… Sequenceë³„ íŒ¨í„´ í•œëˆˆì— ë³´ê¸°")

    # 1) rec_num í•„í„°
    rec_options = sorted(mil_raw["rec_num"].unique())
    rec_selected = st.selectbox("rec_num ì„ íƒ", rec_options)
    mil = mil_raw[mil_raw["rec_num"] == rec_selected].copy()
    mil = add_time_features(mil)

    # 2) ì‹œí€€ìŠ¤ë³„ ì–‘í’ˆ/ë¶ˆëŸ‰ ë¼ë²¨
    seq_status = (
        mil.groupby("sequence_index")["failure"]
           .agg(lambda s: -1 if (s == -1).any() else 1)
           .reset_index(name="seq_failure")
    )

    seq_status["status_label"] = seq_status["seq_failure"].map({
        -1: "âš  ",
         1: "âœ… ",
    })

    seq_status["option_label"] = seq_status.apply(
        lambda r: f"{int(r.sequence_index)} - {r.status_label}", axis=1
    )

    label_to_seq = dict(
        zip(seq_status["option_label"], seq_status["sequence_index"])
    )

    # 3) ì—¬ëŸ¬ ì‹œí€€ìŠ¤ ì„ íƒ
    st.markdown("#### ì‹œí€€ìŠ¤ ì„ íƒ")
    options = seq_status["option_label"].tolist()
    default_vals = options[:3] if len(options) >= 3 else options

    selected_labels = st.multiselect(
        "Sequence ì„ íƒ(âœ…ì–‘í’ˆ, âš ë¶ˆëŸ‰)",
        options=options,
        default=default_vals
    )

    if not selected_labels:
        st.info("ìµœì†Œ 1ê°œ ì´ìƒì˜ ì‹œí€€ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        st.stop()

    selected_seqs = [label_to_seq[l] for l in selected_labels]

    # 4) ì„ íƒëœ ì‹œí€€ìŠ¤ ë°ì´í„°ë§Œ ì‚¬ìš©
    mil_sel = mil[mil["sequence_index"].isin(selected_seqs)].copy()
    mil_sel = mil_sel.sort_values(["sequence_index", "pk_datetime"])

    # 5) ê° ì‹œí€€ìŠ¤ë³„ ì •ê·œí™” ì‹œê°„(norm_time = 0~1)
    mil_sel["t_min"] = mil_sel.groupby("sequence_index")["pk_datetime"].transform("min")
    mil_sel["t_max"] = mil_sel.groupby("sequence_index")["pk_datetime"].transform("max")

    dt = (mil_sel["pk_datetime"] - mil_sel["t_min"]).dt.total_seconds()
    total = (mil_sel["t_max"] - mil_sel["t_min"]).dt.total_seconds().replace(0, 1)
    mil_sel["norm_time"] = dt / total

    st.caption(
        "â€» xì¶•ì€ ê° ì‹œí€€ìŠ¤ì˜ ì‹œì‘-ëì„ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”í•œ ìƒëŒ€ ì‹œê°„ì…ë‹ˆë‹¤. ")

    charts = []
    for sensor in ["ampere", "volt", "temperature"]:
        df_s = mil_sel[["sequence_index", "norm_time", sensor]].copy()

        chart = (
            alt.Chart(df_s)
            .mark_line()
            .encode(
                x=alt.X("norm_time:Q", title=""),
                y=alt.Y(f"{sensor}:Q", title=sensor),
                color=alt.Color(
                    "sequence_index:N",
                    title="Sequence",
                    legend=alt.Legend(orient="right")
                ),
                tooltip=[
                    alt.Tooltip("sequence_index:N", title="Sequence"),
                    alt.Tooltip("norm_time:Q", title="ì‹œê°„(0~1)", format=".2f"),
                    alt.Tooltip(f"{sensor}:Q", title=sensor, format=".1f"),
                ],
            )
            .properties(height=220)
        )
        charts.append(chart)

    combined = alt.vconcat(*charts).resolve_scale(y="independent")
    st.altair_chart(combined, use_container_width=True)


# ===================================
# 4-3. ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ê²°ê³¼
# ===================================
elif page == "ğŸ’» ML ì˜ˆì¸¡ ê²°ê³¼":
    st.subheader("ğŸ’» ML ì˜ˆì¸¡ ê²°ê³¼")

    # ê³µí†µ: Test í™•ë¥  ì˜ˆì¸¡
    X_test_rf = X_test[feature_names]
    y_proba = rf_model.predict_proba(X_test_rf)[:, 1]
    y_proba_s = pd.Series(y_proba, index=y_test.index)

    # 1) Feature Importance
    st.markdown("### 1. Feature Importance (RF ê¸°ì¤€)")

    importances = rf_model.feature_importances_
    fi = pd.Series(importances, index=feature_names).sort_values(ascending=False)

    fi_df = pd.DataFrame({
        "feature": fi.index,
        "importance": fi.values
    })

    fi_chart = (
        alt.Chart(fi_df)
        .mark_bar()
        .encode(
            x=alt.X(
                "feature:N",
                sort='-y',
                axis=alt.Axis(labelAngle=-45, title="Feature")
            ),
            y=alt.Y("importance:Q", title="Importance"),
            tooltip=[
                alt.Tooltip("feature:N", title="Feature"),
                alt.Tooltip("importance:Q", title="Importance", format=".4f"),
            ],
        )
        .properties(height=350)
    )

    st.altair_chart(fi_chart, use_container_width=True)

    # 2) ì„ê³„ê°’ + KPI / Confusion Matrix
    st.markdown("### 2. ì„ê³„ê°’ & ì„±ëŠ¥ ì§€í‘œ / Confusion Matrix")

    col_left,col_gap, col_right = st.columns([1,0.2, 1])

    with col_left:
        st.caption("#### ì„ê³„ê°’ & í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ")

        # threshold slider
        if "user_th" in st.session_state:
            default_th = float(st.session_state["user_th"])
        else:
            default_th = float(threshold)

        user_th = st.slider(
            "Threshold (ë¶ˆëŸ‰ìœ¼ë¡œ ì˜ˆì¸¡í•  ìµœì†Œ í™•ë¥ )",
            0.0, 1.0,
            value=default_th,
            step=0.01,
            key="th_slider_ml"
        )
        st.session_state["user_th"] = float(user_th)

        y_pred_user = (y_proba_s >= user_th).astype(int)

        report_dict = classification_report(
            y_test, y_pred_user, output_dict=True, zero_division=0
        )
        acc = report_dict["accuracy"]
        f1_defect = report_dict["1"]["f1-score"]
        recall_defect = report_dict["1"]["recall"]

        # KPI metrics
        m1, m2, m3 = st.columns(3)
        m1.metric("Accuracy", f"{acc*100:.1f} %")
        m2.metric("F1 (ë¶ˆëŸ‰)", f"{f1_defect:.3f}")
        m3.metric("Recall (ë¶ˆëŸ‰)", f"{recall_defect:.3f}")
        



        st.caption("ğŸ“„ ì „ì²´ ë¶„ë¥˜ ë¦¬í¬íŠ¸")
        report_df = classification_report_to_df(report_dict)
        st.dataframe(
            report_df, use_container_width=True, hide_index=False
        )

    with col_gap:
        st.subheader("")


    with col_right:
        st.caption("#### Confusion Matrix")

        cm = confusion_matrix(y_test, y_pred_user)
        cm_df = pd.DataFrame(
            cm,
            index=["Actual 0", "Actual 1"],
            columns=["Pred 0", "Pred 1"]
        ).reset_index().rename(columns={"index": "actual"})

        cm_long = cm_df.melt(
            id_vars="actual",
            var_name="predicted",
            value_name="count"
        )

        # --- Heatmap ---
        heatmap = (
            alt.Chart(cm_long)
            .mark_rect()
            .encode(
                x=alt.X("predicted:N", title="Predicted"),
                y=alt.Y("actual:N", title="Actual"),
                color=alt.Color(
                    "count:Q",
                    scale=alt.Scale(scheme="blues"),
                    legend=alt.Legend(title="Count")
                ),
                tooltip=[
                    alt.Tooltip("actual:N", title="Actual"),
                    alt.Tooltip("predicted:N", title="Predicted"),
                    alt.Tooltip("count:Q", title="Count")
                ],
            )
            .properties(height=500)
        )

        
        text = (
            alt.Chart(cm_long)
            .mark_text(fontSize=14, fontWeight="bold", color="black")
            .encode(
                x="predicted:N",
                y="actual:N",
                text="count:Q",
            )
        )

        st.altair_chart(heatmap + text, use_container_width=True)





# ---------- ë¶ˆëŸ‰ ì›ì¸ ë¶„ì„ ----------
elif page == "ë¶ˆëŸ‰ ì›ì¸ ë¶„ì„":
    st.subheader("ğŸ§¯ ë¶ˆëŸ‰ ì‹œí€€ìŠ¤ ìƒì„¸ ì›ì¸ ë³´ê¸°")

    # 0) ML í˜ì´ì§€ì™€ ì—°ë™ë˜ëŠ” Threshold ìŠ¬ë¼ì´ë”
    if "user_th" in st.session_state:
        th_default = float(st.session_state["user_th"])
    else:
        th_default = float(threshold)

    user_th = st.slider(
        "Threshold (ë¶ˆëŸ‰ìœ¼ë¡œ ì˜ˆì¸¡í•  ìµœì†Œ í™•ë¥ )",
        0.0, 1.0,
        value=th_default,
        step=0.01,
        key="th_slider_fault"
    )
    st.session_state["user_th"] = float(user_th)

    # ì´ í˜ì´ì§€ì—ì„œë„ test ì˜ˆì¸¡ ë‹¤ì‹œ ê³„ì‚° (ì˜¤ì§„ ì¼€ì´ìŠ¤ìš©)
    X_test_rf = X_test[feature_names]
    y_proba_test = rf_model.predict_proba(X_test_rf)[:, 1]
    y_proba_s = pd.Series(y_proba_test, index=y_test.index)
    y_pred_user = (y_proba_s >= user_th).astype(int)

    # 1) ì‹œí€€ìŠ¤ë³„ ë¶ˆëŸ‰ í™•ë¥  + ì˜¤ì§„ ì¼€ì´ìŠ¤ (ì¢Œ/ìš° ë°°ì¹˜)
    st.markdown("### 1. ì‹œí€€ìŠ¤ë³„ ë¶ˆëŸ‰ í™•ë¥  / ì˜¤ì§„ ì¼€ì´ìŠ¤")

    col_left, col_right = st.columns([1, 1])

    # 1-1) ì‹œí€€ìŠ¤ë³„ ë¶ˆëŸ‰ í™•ë¥  (LEFT)
    with col_left:
        st.markdown("#### ğŸ” ì‹œí€€ìŠ¤ë³„ ë¶ˆëŸ‰ í™•ë¥ ")

        seq_list = sorted(mil_ml["sequence_index"].unique())
        seq_choice = st.selectbox("ì‹œí€€ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”", seq_list, key="seq_choice_fault")
        seq_df = mil_ml[mil_ml["sequence_index"] == seq_choice]

        if len(seq_df) > 0:
            X_seq_seg = seq_df[feature_names]
            proba_seq = rf_model.predict_proba(X_seq_seg)[:, 1]
            proba_seq_s = pd.Series(proba_seq, index=seq_df.index)

            mean_proba = proba_seq_s.mean()
            pred_seq = int(mean_proba >= user_th)

            c1, c2, c3 = st.columns(3)
            c1.metric("í‰ê·  ë¶ˆëŸ‰ í™•ë¥ ", f"{mean_proba:.3f}")
            c2.metric("ì„ê³„ê°’", f"{user_th:.3f}")
            c3.metric("ì˜ˆì¸¡ ê²°ê³¼", "âš  ë¶ˆëŸ‰" if pred_seq == 1 else "âœ… ì–‘í’ˆ")

            with st.expander("ì„ íƒ ì‹œí€€ìŠ¤ (ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜) ìƒì„¸ ë³´ê¸°", expanded=False):
                seq_view = seq_df.copy()
                seq_view["ë¶ˆëŸ‰í™•ë¥ (ëª¨ë¸)"] = proba_seq_s
                st.dataframe(seq_view)
        else:
            st.info("í•´ë‹¹ ì‹œí€€ìŠ¤ ë°ì´í„° ì—†ìŒ")

    # 1-2) ì˜¤ì§„ ì¼€ì´ìŠ¤ (RIGHT)
    with col_right:
        st.markdown("#### âŒ ì˜¤ì§„(ì˜ˆì¸¡ í‹€ë¦°) ì¼€ì´ìŠ¤")

        wrong_mask = (y_test != y_pred_user)
        wrong_idx = y_test.index[wrong_mask]

        if len(wrong_idx) == 0:
            st.success("í˜„ì¬ ì˜¤ì§„ ì¼€ì´ìŠ¤ ì—†ìŒ ğŸ‰")
        else:
            st.write(f"ì´ **{len(wrong_idx)}ê±´**ì˜ ì˜¤ì§„ ì¼€ì´ìŠ¤")
            with st.expander("ì˜¤ì§„ ì¼€ì´ìŠ¤ ìƒì„¸ ë³´ê¸°", expanded=False):
                wrong_cases = mil_ml.loc[wrong_idx].copy()
                wrong_cases["ì‹¤ì œê°’(y_true)"] = y_test.loc[wrong_idx]
                wrong_cases["ì˜ˆì¸¡ê°’(y_pred)"] = y_pred_user.loc[wrong_idx]
                wrong_cases["ë¶ˆëŸ‰í™•ë¥ (ëª¨ë¸)"] = y_proba_s.loc[wrong_idx]
                st.dataframe(wrong_cases)
